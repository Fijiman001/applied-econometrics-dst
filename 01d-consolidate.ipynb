{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3019da4-a1bd-4279-8446-2b5e5c4fca32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/matthew/Documents/TSE/AppliedEconometrics/repo/utils.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gzip\n",
    "import os\n",
    "import importlib\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "from io import TextIOWrapper\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# utils is our local utility module\n",
    "# if we change utils.py, and re-run a normal 'import'\n",
    "# python won't reload it by default. (Since it's already loaded.)\n",
    "# So we force a reload\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d772e32d-0083-4320-8dd1-de9efdc4bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_data_dir = '/home/matthew/Documents/TSE/AppliedEconometrics/repo/data/'\n",
    "laptop_data_dir = '/home/matthew/data/'\n",
    "\n",
    "# output of the previous script\n",
    "source_dir = os.path.join(laptop_data_dir, '01-D-split-mapped-csv-done')\n",
    "\n",
    "\n",
    "# the parquet files go here\n",
    "dest_dir = os.path.join(laptop_data_dir, '01-D-consolidate-csv')\n",
    "\n",
    "schema_path = os.path.join(repo_data_dir, 'schemas.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0333dc1d-4eb9-4ee8-8240-05bca8c612e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_col_name = 'SCHEMA_VERSION'\n",
    "top_timestamp_col_name = 'TOP_TIMESTAMP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1060466c-70d4-448e-80af-a7ad2835636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(schema_path, 'r') as f:\n",
    "    schemas = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34ba3ec3-ced0-4562-a62f-c33416aacb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = utils.Logger(os.path.join(repo_data_dir, 'logs.txt'))\n",
    "logger.info(\"Initialising Logger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b45467f-955e-48e1-be69-0d365a403a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [55:57, 15.54s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m reader:\n\u001b[1;32m     26\u001b[0m                     row\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[1;32m     27\u001b[0m                         version_col_name: schema_version,\n\u001b[1;32m     28\u001b[0m                         top_timestamp_col_name: top_timestamp\n\u001b[1;32m     29\u001b[0m                     })\n\u001b[0;32m---> 30\u001b[0m                     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(dest_path):\n",
      "File \u001b[0;32m/usr/lib/python3.11/csv.py:154\u001b[0m, in \u001b[0;36mDictWriter.writerow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterow\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter\u001b[38;5;241m.\u001b[39mwriterow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict_to_list(rowdict))\n",
      "File \u001b[0;32m/usr/lib/python3.11/csv.py:151\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict contains fields not in fieldnames: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m                          \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (rowdict\u001b[38;5;241m.\u001b[39mget(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestval) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "table = 'DISPATCHLOAD'\n",
    "table_source_dir = os.path.join(source_dir, table)\n",
    "dest_path = os.path.join(dest_dir, table + '.csv.gz')\n",
    "\n",
    "in_columns = list(schemas[table]['columns'].keys())\n",
    "out_columns = in_columns + [version_col_name, top_timestamp_col_name]\n",
    "\n",
    "try:\n",
    "    utils.create_dir(file=dest_path)\n",
    "    with gzip.open(dest_path, 'wt', newline='', compresslevel=2) as f_dest_str:\n",
    "        writer = csv.DictWriter(f_dest_str, fieldnames=out_columns)\n",
    "        writer.writeheader()\n",
    "    \n",
    "        for csv_path in tqdm(utils.walk(table_source_dir)):\n",
    "            match = re.search(f\"/{version_col_name}=(\\d+)/\", csv_path)\n",
    "            assert match, f\"Unable to extract schema version from {csv_path}\"\n",
    "            schema_version = int(match.group(1))\n",
    "        \n",
    "            match = re.search(f\"/{top_timestamp_col_name}=([\\d_]+)/\", csv_path)\n",
    "            assert match, f\"Unable to extract top_timestamp from {csv_path}\"\n",
    "            top_timestamp = match.group(1)\n",
    "\n",
    "            with gzip.open(csv_path, 'rt', newline='') as f_src_str:\n",
    "                reader = csv.DictReader(f_src_str)\n",
    "                for row in reader:\n",
    "                    row.update({\n",
    "                        version_col_name: schema_version,\n",
    "                        top_timestamp_col_name: top_timestamp\n",
    "                    })\n",
    "                    writer.writerow(row)\n",
    "\n",
    "            \n",
    "except:\n",
    "    if os.path.exists(dest_path):\n",
    "        os.remove(dest_path)\n",
    "    raise\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596e0e5b-a602-4ea4-988a-1378451316c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
