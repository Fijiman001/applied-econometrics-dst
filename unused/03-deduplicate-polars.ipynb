{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f7f6412a-f652-4af9-b6be-2c58f1480bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/matthew/Documents/TSE/AppliedEconometrics/repo/utils.py'>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.parse\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "# utils is our local utility module\n",
    "# if we change utils.py, and re-run a normal 'import'\n",
    "# python won't reload it by default. (Since it's already loaded.)\n",
    "# So we force a reload\n",
    "import utils\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "47dec646-02c8-4670-8dc4-e367d296f63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/home/matthew/data/\"\n",
    "source_dir = f\"{data_dir}/01-D-parquet-pyarrow-dataset/\"\n",
    "source_path = f\"{source_dir}/DISPATCHLOAD/part-0.parquet\"\n",
    "intermediate_dir = f\"{data_dir}/03-A-polars-partitioned-by-region/DISPATCHLOAD/\"\n",
    "dest_dir = f\"{data_dir}/03-A-polars-joined/\"\n",
    "dudetailsummary_path = os.path.join(source_dir, 'DUDETAILSUMMARY', 'part-0.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f9bb3-42d1-4865-bd99-a61735791f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is 5 minute intervals\n",
    "intervals_per_hour = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b6ed85d-2a50-4e58-98b5-0a90f30b387e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duids = (\n",
    "    pl.scan_parquet(source_path, low_memory=True)\n",
    "    .select(pl.col(\"DUID\").unique())\n",
    "    .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3f3e65f-9ce0-4056-ad46-22291956ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "duids = [x['DUID'] for x in duids.to_dicts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "80b8b0c7-c72a-4ded-b4d7-b2d52fd9f241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>DUID</th><th>CO2E_EMISSIONS_FACTOR</th></tr><tr><td>str</td><td>f64</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 2)\n",
       "┌──────┬───────────────────────┐\n",
       "│ DUID ┆ CO2E_EMISSIONS_FACTOR │\n",
       "│ ---  ┆ ---                   │\n",
       "│ str  ┆ f64                   │\n",
       "╞══════╪═══════════════════════╡\n",
       "└──────┴───────────────────────┘"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# get emissions data per genunit\n",
    "genunits_path = os.path.join(source_dir, 'GENUNITS', 'part-0.parquet')\n",
    "genset_emissions = (\n",
    "    pl.scan_parquet(genunits_path)\n",
    "    .filter(pl.col(\"GENSETTYPE\") == \"GENERATOR\")\n",
    "    .sort(\"LASTCHANGED\", descending=True)\n",
    "    .unique(subset=[\"GENSETID\"], keep='first')\n",
    "    .select(\"GENSETID\", \"CO2E_EMISSIONS_FACTOR\", \"MAXCAPACITY\")\n",
    ")\n",
    "\n",
    "dualloc_path = os.path.join(source_dir, 'DUALLOC', 'part-0.parquet')\n",
    "duid_gensetid = (\n",
    "    pl.scan_parquet(dualloc_path)\n",
    "    .select(\"DUID\", \"GENSETID\")\n",
    ")\n",
    "\n",
    "emissions_by_duid = (\n",
    "    duid_gensetid\n",
    "    .join(genset_emissions, left_on=\"GENSETID\", right_on=\"GENSETID\")\n",
    "    # now do a weighted average of CO2E_EMISSIONS_FACTOR\n",
    "    # group by DUID\n",
    "    # weight by MAXCAPACITY\n",
    "    .with_columns((pl.col(\"CO2E_EMISSIONS_FACTOR\") * pl.col(\"MAXCAPACITY\")).alias(\"SCALED_CO2\"))\n",
    "    .group_by(\"DUID\")\n",
    "    .sum()\n",
    "    .with_columns((pl.col(\"SCALED_CO2\") / pl.col(\"MAXCAPACITY\")).alias(\"CO2E_EMISSIONS_FACTOR\"))\n",
    "    .select(\"DUID\", \"CO2E_EMISSIONS_FACTOR\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b998861f-5d64-449a-904f-2e6ded16db9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 543/543 [2:38:50<00:00, 17.55s/it]\n"
     ]
    }
   ],
   "source": [
    "utils.create_dir(file=intermediate_dir)\n",
    "\n",
    "for duid in tqdm(duids):\n",
    "\n",
    "    region_duid = (\n",
    "        pl.scan_parquet(dudetailsummary_path)\n",
    "        .filter(pl.col(\"DUID\") == pl.lit(duid))\n",
    "        .filter(pl.col(\"REGIONID\") != \"SNOWY1\")\n",
    "        .sort(\"START_DATE\", descending=False)\n",
    "        .select(\"REGIONID\", \"DUID\")\n",
    "        .last()\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    (\n",
    "        pl.scan_parquet(source_path, low_memory=False)\n",
    "        .filter(pl.col(\"INTERVENTION\") == 0)\n",
    "        .filter(pl.col(\"DUID\") == duid)\n",
    "        .select(pl.exclude(\"INTERVENTION\"))\n",
    "\n",
    "        # now that it's filtered\n",
    "        # deduplicate\n",
    "        .sort(\"SETTLEMENTDATE\", \"RUNNO\", \"SCHEMA_VERSION\", \"TOP_TIMESTAMP\", \"LASTCHANGED\", descending=[False, False, True, True, True])\n",
    "        .group_by(\"SETTLEMENTDATE\")\n",
    "        .first()\n",
    "        \n",
    "\n",
    "        # now combine INITIALMW and TOTALCLEARED\n",
    "        # NEXT_POWER is the value of INITIALMW in the next time (data already sorted in ascending time)\n",
    "        # but for the last value (no next INITIALMW), choose TOTALCLEARED\n",
    "        # the .shift() operator requires that we call .collect()\n",
    "        # but by now the data is small enough to do that\n",
    "        .select(\"SETTLEMENTDATE\", \"INITIALMW\", \"TOTALCLEARED\")\n",
    "        .collect()\n",
    "        .with_columns(pl.coalesce(pl.col('INITIALMW').shift(-1), \"TOTALCLEARED\").alias(\"NEXT_POWER\"))\n",
    "        .with_columns(((pl.col(\"INITIALMW\") + pl.col(\"NEXT_POWER\"))/2).alias(\"POWER\"))\n",
    "\n",
    "        \n",
    "        # add DUID back, as a literal (to be faster)\n",
    "        .with_columns(pl.lit(duid).alias(\"DUID\"))\n",
    "        # add region (same value for all rows)\n",
    "        .join(region_duid, left_on=\"DUID\", right_on=\"DUID\")\n",
    "        # add emissions (same value for all rows\n",
    "        #.join(emissions_by_duid, left_on=\"DUID\", right_on=\"DUID\")\n",
    "        \n",
    "        # drop everything except what we care about\n",
    "        .select(\"REGIONID\", \"DUID\", \"SETTLEMENTDATE\", \"POWER\")\n",
    "        .with_columns(pl.col(\"SETTLEMENTDATE\").dt.year().alias(\"SETTLEMENTDATE_YEAR\"))\n",
    "        .with_columns(pl.col(\"SETTLEMENTDATE\").dt.month().alias(\"SETTLEMENTDATE_MONTH\"))\n",
    "        .write_parquet(intermediate_dir, \n",
    "                       use_pyarrow=True,\n",
    "                       pyarrow_options={\n",
    "                            \"partition_cols\": [\"REGIONID\", \"SETTLEMENTDATE_YEAR\", \"SETTLEMENTDATE_MONTH\", \"DUID\"],\n",
    "                            \"existing_data_behavior\": \"overwrite_or_ignore\"\n",
    "                        })\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d6ec4a-14d5-42ee-930c-0af24685e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get emissions data per genunit\n",
    "genunits_path = os.path.join(source_dir, 'GENUNITS', 'part-0.parquet')\n",
    "genset_emissions = (\n",
    "    pl.scan_parquet(genunits_path)\n",
    "    .filter(pl.col(\"GENSETTYPE\") == \"GENERATOR\")\n",
    "    .sort(\"LASTCHANGED\", descending=True)\n",
    "    .unique(subset=[\"GENSETID\"], keep='first')\n",
    "    .select(\"GENSETID\", \"CO2E_EMISSIONS_FACTOR\", \"MAXCAPACITY\")\n",
    ")\n",
    "\n",
    "dualloc_path = os.path.join(source_dir, 'DUALLOC', 'part-0.parquet')\n",
    "duid_gensetid = (\n",
    "    pl.scan_parquet(dualloc_path)\n",
    "    .select(\"DUID\", \"GENSETID\")\n",
    ")\n",
    "\n",
    "emissions_by_duid = (\n",
    "    duid_gensetid\n",
    "    .join(genset_emissions, left_on=\"GENSETID\", right_on=\"GENSETID\")\n",
    "    # now do a weighted average of CO2E_EMISSIONS_FACTOR\n",
    "    # group by DUID\n",
    "    # weight by MAXCAPACITY\n",
    "    .with_columns((pl.col(\"CO2E_EMISSIONS_FACTOR\") * pl.col(\"MAXCAPACITY\")).alias(\"SCALED_CO2\"))\n",
    "    .group_by(\"DUID\")\n",
    "    .sum()\n",
    "    .with_columns((pl.col(\"SCALED_CO2\") / pl.col(\"MAXCAPACITY\")).alias(\"CO2E_EMISSIONS_FACTOR\"))\n",
    "    .select(\"DUID\", \"CO2E_EMISSIONS_FACTOR\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "008972b3-981d-43fa-81e0-d84a59709e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (1, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>REGIONID</th><th>DUID</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;QLD1&quot;</td><td>&quot;CALL_A_2&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (1, 2)\n",
       "┌──────────┬──────────┐\n",
       "│ REGIONID ┆ DUID     │\n",
       "│ ---      ┆ ---      │\n",
       "│ str      ┆ str      │\n",
       "╞══════════╪══════════╡\n",
       "│ QLD1     ┆ CALL_A_2 │\n",
       "└──────────┴──────────┘"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_dir = \"/home/matthew/data/03-A-polars-partitioned-by-region/DISPATCHLOAD\"\n",
    "duids = set()\n",
    "\n",
    "for regionid in tqdm(['QLD1', 'NSW1', 'VIC1', 'SA1', 'TAS1']):\n",
    "    region_lfs = []\n",
    "    for year in range(2009, 2023+1):\n",
    "        for month in range(1, 12+1):\n",
    "            pq_src_dir = f\"{intermediate_dir}/REGIONID={regionid}/SETTLEMENTDATE_YEAR={year}/SETTLEMENTDATE_MONTH={month}/\"\n",
    "            monthly_lfs = []\n",
    "            for pq_src_path in utils.walk(pq_src_dir):\n",
    "                match = re.search(r\"DUID=([^/]+)\", pq_src_path)\n",
    "                assert match, f\"Can't find DUID from {pq_src_path}\"\n",
    "                duid = urllib.parse.unquote(match.group(1))\n",
    "                duids.add(duid)\n",
    "                monthly_lfs.append(\n",
    "                    pl.scan_parquet(pq_src_path)\n",
    "                    .with_columns(pl.lit(duid).alias(\"DUID\"))\n",
    "                )\n",
    "            if monthly_lfs:\n",
    "                monthly_lf = (\n",
    "                    pl.concat(monthly_lfs)\n",
    "                    .join(emissions_by_duid, left_on=\"DUID\", right_on=\"DUID\")\n",
    "                    .with_columns((pl.col(\"POWER\") / intervals_per_hour).alias(\"ENERGY_MWH\"))\n",
    "                    .with_columns((pl.col(\"CO2E_EMISSIONS_FACTOR\") * pl.col(\"ENERGY_MWH\")).alias(\"CO2_T\"))\n",
    "                    .group_by(\"SETTLEMENTDATE\")\n",
    "                    .sum()\n",
    "                    .select(\"SETTLEMENTDATE\", \"ENERGY_MWH\", \"CO2_T\")\n",
    "                )\n",
    "                region_lfs.append(monthly_lf)\n",
    "                #print(f\"Found {len(monthly_lfs)} files in {pq_src_dir}\")\n",
    "                break\n",
    "            #else:\n",
    "                #print(f\"Warning: no files found in {pq_src_dir}\")\n",
    "            \n",
    "    pl.concat(region_lfs).sink_parquet(f\"{dest_dir}/REGIONID={regionid}/part-0.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
